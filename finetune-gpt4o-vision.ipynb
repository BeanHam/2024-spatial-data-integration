{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0991d177",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/binhan/anaconda3/lib/python3.11/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['torch_dtype']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "import base64\n",
    "import string\n",
    "import datasets\n",
    "import argparse\n",
    "import numpy as np\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from os import path, makedirs, getenv, mkdir\n",
    "from huggingface_hub import login as hf_login\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ae255d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "341ded7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def encode_image(image_path):\n",
    "#    img=Image.open(image_path)\n",
    "#    img=img.resize((int(0.25*img.size[0]), int(0.25*img.size[1])))\n",
    "#    return base64.b64encode(img.tobytes()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8e73326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_for_finetuning(system_prompt: str,\n",
    "                          user_input: str,\n",
    "                          base64_image: str,\n",
    "                          assistant_output: str) -> str:\n",
    "    \"\"\"\n",
    "    Format data in JSON for fine-tuning an OpenAI chatbot model.\n",
    "    \"\"\"\n",
    "\n",
    "    return json.dumps(\n",
    "        {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt}, \n",
    "                {\"role\": \"user\", \"content\": user_input},\n",
    "                { \"role\": \"user\", \"content\": [\n",
    "                    {\"type\": \"image_url\",\n",
    "                     \"image_url\": {\"url\":  f\"data:image/jpeg;base64,{base64_image}\"}\n",
    "                    }]\n",
    "                },\n",
    "                {\"role\": \"assistant\", \"content\": assistant_output}\n",
    "            ]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e87be0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "176bbf48b30249f8b498d10701f3e53f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Fine-tune a spatial-join model.')\n",
    "parser.add_argument('--model_id', type=str, default='gpt-4o-mini-2024-07-18', help='The model ID to fine-tune.')\n",
    "parser.add_argument('--OPENAI_API_KEY', type=str, help='API key to finetune GPT-4o')\n",
    "parser.add_argument('--dataset', type=str, default='beanham/spatial_join', help='The dataset to use for fine-tuning.')\n",
    "parser.add_argument('--formatted_data_dir', type=str, help='The directory to save the formatted data to', default='formatted_data')\n",
    "args = parser.parse_args(args=[])\n",
    "hf_login()\n",
    "if not path.exists(args.formatted_data_dir):\n",
    "    mkdir(args.formatted_data_dir)\n",
    "    print(f'Created directory {args.formatted_data_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d40c0d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths={\n",
    "    'p_path':'../2024-spatial-join-exp/join_task_imgs/positive/',\n",
    "    'n_path':'../2024-spatial-join-exp/join_task_imgs/negative/',\n",
    "    'fp_path':'../2024-spatial-join-exp/join_task_imgs/false_positive/',\n",
    "    'fn_path':'../2024-spatial-join-exp/join_task_imgs/false_negative/'\n",
    "}\n",
    "system_message = \"\"\"\n",
    "You are a helpful geospatial analysis assistant! I will provide you with a pair of (sidewalk, road) information in GeoJSON format, along with a satellite image visualizing the sidewalk (red line) and road (blue line). Please help me identify whether the sidewalk is alongside the paired road, such that the sidewalk is adjacent and parellele to the road. If it is, please return 1; otherwise, return 0.\n",
    "    \n",
    "Please just return 0 or 1. No explaination needed.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6bd7949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing data...\n"
     ]
    }
   ],
   "source": [
    "# ----------------------\n",
    "# Load Data\n",
    "# ----------------------\n",
    "print('Downloading and preparing data...')\n",
    "data = get_dataset_slices(args.dataset)\n",
    "train = data['train']\n",
    "val = data['val']\n",
    "\n",
    "with open('../2024-spatial-join-exp/join_task_data/index.txt', 'r') as f:\n",
    "    index = json.load(f)\n",
    "train_index=index['train']\n",
    "val_index=index['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "baf56b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2743/2743 [10:09<00:00,  4.50it/s]\n"
     ]
    }
   ],
   "source": [
    "train_formatted=[]\n",
    "for i in tqdm(range(len(train))):\n",
    "    sidewalk = \"Sidewalk: \"+str(train['sidewalk'][i])\n",
    "    road = \"Road: \"+str(train['road'][i])\n",
    "    user_message=sidewalk+road\n",
    "    img_name=train_index[i]\n",
    "    if 'positive' in img_name:img_path=paths['p_path']+img_name+'.png'\n",
    "    else:img_path=paths['n_path']+img_name+'.png'\n",
    "    base64_image = encode_image(img_path)\n",
    "    label=\"Lable: \"+str(train['label'][i])    \n",
    "    train_formatted.append(format_for_finetuning(system_message, user_message, base64_image, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd62c1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 305/305 [00:07<00:00, 42.39it/s]\n"
     ]
    }
   ],
   "source": [
    "val_formatted=[]\n",
    "for i in tqdm(range(len(val))):\n",
    "    sidewalk = \"Sidewalk: \"+str(val['sidewalk'][i])\n",
    "    road = \"Road: \"+str(val['road'][i])\n",
    "    user_message=sidewalk+road\n",
    "    img_name=val_index[i]\n",
    "    if 'positive' in img_name:img_path=paths['p_path']+img_name+'.png'\n",
    "    else:img_path=paths['n_path']+img_name+'.png'\n",
    "    base64_image = encode_image(img_path)\n",
    "    label=\"Lable: \"+str(val['label'][i])    \n",
    "    val_formatted.append(format_for_finetuning(system_message, user_message, base64_image, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0365f88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_formatted_join ='\\n'.join(train_formatted)\n",
    "val_formatted_join ='\\n'.join(val_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54bc9b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing formatted data to file...\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------\n",
    "# Write the formatted data to a file\n",
    "# ----------------------------------\n",
    "print('Writing formatted data to file...')\n",
    "with open(path.join(args.formatted_data_dir, 'gpt4o_vision_train.jsonl'), 'w') as f:\n",
    "    f.write(train_formatted_join)\n",
    "with open(path.join(args.formatted_data_dir, 'gpt4o_vision_val.jsonl'), 'w') as f:\n",
    "    f.write(val_formatted_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2611d537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------\n",
    "# Set the OpenAI API key and create a client\n",
    "# ----------------------------------        \n",
    "client = OpenAI(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbec7728",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the training dataset\n",
    "train_response = client.files.create(\n",
    "    file=open(path.join(args.formatted_data_dir, 'gpt4o_vision_train.jsonl'), \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")\n",
    "val_response = client.files.create(\n",
    "    file=open(path.join(args.formatted_data_dir, 'gpt4o_vision_val.jsonl'), \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19231545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the fine-tuning job\n",
    "job_response = client.fine_tuning.jobs.create(\n",
    "    training_file=train_response.id,\n",
    "    validation_file=val_response.id,\n",
    "    model=args.model_id,\n",
    "    hyperparameters={\n",
    "        \"n_epochs\": 5,\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
