{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d37fe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scienceplots\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from datasets import load_dataset,concatenate_datasets\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9e9392c-70b1-4dfa-943c-c7cb15cddd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(data, metric_name, metric_value):    \n",
    "    if metric_name == 'degree':\n",
    "        p_id = data.filter(lambda x: ((x['label']==1) & (x['min_angle']<=metric_value)))\n",
    "        p_ood = data.filter(lambda x: ((x['label']==1) & (x['min_angle']>metric_value)))        \n",
    "        n_id = data.filter(lambda x: ((x['label']==0) & (x['min_angle']>metric_value)))\n",
    "        n_ood = data.filter(lambda x: ((x['label']==0) & (x['min_angle']<=metric_value)))\n",
    "        id_data=concatenate_datasets([p_id,n_id])\n",
    "        ood_data=concatenate_datasets([p_ood,n_ood])        \n",
    "    elif metric_name == 'distance':\n",
    "        p_id = data.filter(lambda x: ((x['label']==1) & (x['euc_dist']>=metric_value)))\n",
    "        p_ood = data.filter(lambda x: ((x['label']==1) & (x['euc_dist']<metric_value)))        \n",
    "        n_id = data.filter(lambda x: ((x['label']==0) & (x['euc_dist']<metric_value)))\n",
    "        n_ood = data.filter(lambda x: ((x['label']==0) & (x['euc_dist']>=metric_value)))        \n",
    "        id_data=concatenate_datasets([p_id,n_id])\n",
    "        ood_data=concatenate_datasets([p_ood,n_ood])    \n",
    "    return id_data, ood_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "075a0fbd-d72b-4e03-a358-af91e1a58d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_calculation(data):\n",
    "    gt=data['label']\n",
    "    pred=data['pred']\n",
    "    acc=accuracy_score(gt, pred)\n",
    "    confusion=confusion_matrix(gt, pred)\n",
    "    fpr=confusion[0,1]/len(gt) ## predict to be 1; actual 0\n",
    "    fnr=confusion[1,0]/len(gt) ## predict to be 0; actual 1\n",
    "    return acc,fpr,fnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96bb0e2e-cdbc-4dea-bff8-3bd35405f729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_processing(data, model, metric_name, metric_value):\n",
    "    \n",
    "    ## load ground truth & predictions\n",
    "    gt=np.array(data['label'])\n",
    "    if model == 'heuristic':\n",
    "        if metric_name=='degree':\n",
    "            pred=np.array(data['min_angle'])<=metric_value\n",
    "        elif metric_name == 'distance':\n",
    "            pred=np.array(data['euc_dist'])>=metric_value\n",
    "    elif model == 'bert':\n",
    "        pred=np.load(f'{metric_name}/{model}_{metric_name}_{metric_value}_weak.npy')        \n",
    "    else:\n",
    "        raw_pred=np.load(f'{metric_name}/{model}_{metric_name}_{metric_value}_weak.npy')\n",
    "        pred=[]\n",
    "        for i in range(len(raw_pred)):\n",
    "            try:\n",
    "                pred.append(int(raw_pred[i].replace('<|eot_id|>', '')\\\n",
    "                                      .replace('</s>', '')\\\n",
    "                                      .split('Label:')[1]\\\n",
    "                                      .strip()))\n",
    "            except:\n",
    "                pred.append(2)\n",
    "    data=data.add_column(\"pred\", np.array(pred))\n",
    "    id_data, ood_data=filter_data(data, metric_name, metric_value)\n",
    "    \n",
    "    return data,id_data,ood_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e646eecb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>metric</th>\n",
       "      <th>metric_value</th>\n",
       "      <th>acc</th>\n",
       "      <th>fpr</th>\n",
       "      <th>fnr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>heuristic</td>\n",
       "      <td>degree</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857283</td>\n",
       "      <td>0.030629</td>\n",
       "      <td>0.112089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llama3</td>\n",
       "      <td>degree</td>\n",
       "      <td>1</td>\n",
       "      <td>0.825676</td>\n",
       "      <td>0.037797</td>\n",
       "      <td>0.134572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model  metric  metric_value       acc       fpr       fnr\n",
       "0  heuristic  degree             1  0.857283  0.030629  0.112089\n",
       "1     llama3  degree             1  0.825676  0.037797  0.134572"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"beanham/spatial_join_dataset\")\n",
    "test=ds['test']\n",
    "metric_name='degree'\n",
    "models=['heuristic','llama3']\n",
    "metric_values=[1]\n",
    "results=[]\n",
    "for model in models:\n",
    "    for metric_value in metric_values:\n",
    "        data,id_data,ood_data=post_processing(test,model,metric_name,metric_value)\n",
    "        acc,fpr,fnr=metric_calculation(data)\n",
    "        results.append([model, metric_name, metric_value, acc,fpr,fnr])\n",
    "results=pd.DataFrame(results, columns=['model','metric','metric_value','acc','fpr','fnr'])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98def1eb-c738-47d5-89b2-7ff0ae27225d",
   "metadata": {},
   "source": [
    "# Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49ceba3f-76f9-4eb0-91fd-a839631e9639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>metric</th>\n",
       "      <th>metric_value</th>\n",
       "      <th>acc</th>\n",
       "      <th>fpr</th>\n",
       "      <th>fnr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>heuristic</td>\n",
       "      <td>distance</td>\n",
       "      <td>1</td>\n",
       "      <td>0.846204</td>\n",
       "      <td>0.152493</td>\n",
       "      <td>0.001303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llama3</td>\n",
       "      <td>distance</td>\n",
       "      <td>1</td>\n",
       "      <td>0.854676</td>\n",
       "      <td>0.117628</td>\n",
       "      <td>0.025741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model    metric  metric_value       acc       fpr       fnr\n",
       "0  heuristic  distance             1  0.846204  0.152493  0.001303\n",
       "1     llama3  distance             1  0.854676  0.117628  0.025741"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_name='distance'\n",
    "models=['heuristic','llama3']\n",
    "metric_values=[1]\n",
    "results=[]\n",
    "for model in models:\n",
    "    for metric_value in metric_values:\n",
    "        data,id_data,ood_data=post_processing(test,model,metric_name,metric_value)\n",
    "        acc,fpr,fnr=metric_calculation(data)\n",
    "        results.append([model, metric_name, metric_value, acc,fpr,fnr])\n",
    "results=pd.DataFrame(results, columns=['model','metric','metric_value','acc','fpr','fnr'])\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
