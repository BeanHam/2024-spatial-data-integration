{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d37fe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import product\n",
    "from collections import Counter\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a145510-b475-4e84-908a-f0fdae6d4df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_calculation(pred, gt):    \n",
    "    acc=accuracy_score(gt, pred)\n",
    "    f1=f1_score(gt, pred, average='macro')\n",
    "    confusion=confusion_matrix(gt, pred)\n",
    "    fpr=confusion[0,1]/len(gt) ## predict to be 1; actual 0\n",
    "    fnr=confusion[1,0]/len(gt) ## predict to be 0; actual 1\n",
    "    return acc, f1, fpr, fnr\n",
    "    \n",
    "def post_processing(pred):\n",
    "    new_pred=[]\n",
    "    for i in pred:\n",
    "        i=i.lower()\n",
    "        if 'response' in i:\n",
    "            try: new_pred.append(i.split('response')[1].split()[1].replace('</s>', ''))\n",
    "            except: new_pred.append(2)\n",
    "        elif 'output' in i:\n",
    "            try: new_pred.append(i.split('output')[1].split()[1].replace('</s>', ''))\n",
    "            except: new_pred.append(2)\n",
    "        else:\n",
    "            try: new_pred.append(i.split()[0].replace('</s>', ''))\n",
    "            except:new_pred.append(2)\n",
    "    new_pred = np.array([int(float(i)) if i in ['0', '0.0', '1', '1.0'] else 2 for i in new_pred])\n",
    "    return new_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75203cf5-8684-4f5c-a3f9-a2f6428c5ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"beanham/spatial_join_dataset\")\n",
    "test=ds['test']\n",
    "gt=np.array(test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50c466ea-d9ed-4ba2-aeab-fcdd861b07e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "metric_values = ['random','worst_single', 'best_single', 'worst_comb', 'best_comb', 'worst_all', 'best_all']\n",
    "for model in ['4o_mini', 'qwen_plus', '4o']:\n",
    "    for value in metric_values:\n",
    "        few_shot_hints=np.load(f'base/{model}_correction/{model}_{value}_few_shot_with_heur_hint_all_correction.npy')\n",
    "        few_shot_values=np.load(f'base/{model}_correction/{model}_{value}_few_shot_with_heur_value_all_correction.npy')\n",
    "        few_shot_hints=post_processing(few_shot_hints)\n",
    "        few_shot_values=post_processing(few_shot_values)\n",
    "        few_hints_metrics=metric_calculation(few_shot_hints, gt)\n",
    "        few_values_metrics=metric_calculation(few_shot_values, gt)\n",
    "        results.append([model, value, 'few_shot_hints', few_hints_metrics[0], few_hints_metrics[1]])\n",
    "        results.append([model, value, 'few_shot_values', few_values_metrics[0], few_values_metrics[1]])\n",
    "results=pd.DataFrame(results, columns=['model', 'value', 'prompt', 'acc', 'f1'])        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ab0390-047c-416f-a9cc-cbb98649a71a",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27e4f22a-416d-4de3-b350-37edcdef4f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_processing_cot(pred, model):\n",
    "\n",
    "    if model=='mistral':\n",
    "        new_pred = [p.replace('</s>', '').split()[0] for p in pred]\n",
    "        new_pred = np.array([int(float(i)) if i in ['0', '0.0', '1', '1.0'] else 2 for i in new_pred])\n",
    "    else:\n",
    "        new_pred=[]        \n",
    "        for p in pred:\n",
    "            if (p.split()[0]=='0') or (p.split()[0]=='1'):\n",
    "                new_pred.append(p.split()[0])\n",
    "            else:\n",
    "                p = p.lower().replace('</s>', '').replace('boxed', '')\n",
    "                splits=[s for s in p.lower().split('\\n') if s != '']\n",
    "                p = ' '.join(splits[-3:]).translate(str.maketrans('', '', string.punctuation))                \n",
    "                if 'response' in p:\n",
    "                    try: new_pred.append([t for t in p.split('response')[-1].split() if t.isnumeric()][0])\n",
    "                    except: new_pred.append(2)\n",
    "                elif 'output' in p:\n",
    "                    try: new_pred.append([t for t in p.split('output')[-1].split() if t.isnumeric()][0])\n",
    "                    except: new_pred.append(2)\n",
    "                elif 'return' in p:\n",
    "                    try: new_pred.append([t for t in p.split('return')[-1].split() if t.isnumeric()][0])\n",
    "                    except: new_pred.append(2)\n",
    "                elif 'result' in p:\n",
    "                    try: new_pred.append([t for t in p.split('result')[-1].split() if t.isnumeric()][0])\n",
    "                    except: new_pred.append(2)\n",
    "                elif 'plaintext' in p:\n",
    "                    try: new_pred.append([t for t in p.split('plaintext')[-1].split() if t.isnumeric()][0])\n",
    "                    except: new_pred.append(2)\n",
    "                elif 'json' in p:\n",
    "                    try: new_pred.append([t for t in p.split('json')[-1].split() if t.isnumeric()][0])\n",
    "                    except: new_pred.append(2)\n",
    "                else:\n",
    "                    try: new_pred.append(p.split()[0])\n",
    "                    except:new_pred.append(2)\n",
    "        new_pred = np.array([int(float(i)) if i in ['0', '0.0', '1', '1.0'] else 2 for i in new_pred])\n",
    "    return new_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "66360a9b-5556-42b7-b684-b6027552af73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model='qwen_plus'\n",
    "config='few_shot_with_heur_value_all'\n",
    "## plain\n",
    "pred=np.load(f'base/{model}/{model}_{config}.npy')\n",
    "pred_proc=post_processing(pred)\n",
    "\n",
    "## cot\n",
    "cot_pred=np.load(f'base/{model}_cot/{model}_{config}_cot.npy')\n",
    "cot_pred_proc=post_processing_cot(cot_pred, model)\n",
    "\n",
    "## correction\n",
    "correction=np.load(f'base/{model}_correction/{model}_best_all_{config}_correction.npy')\n",
    "reviews=np.load(f'base/{model}_correction/{model}_best_all_{config}_correction_reviews.npy')\n",
    "correction_proc=post_processing(correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "864be6e8-5fbe-4ea8-8680-6e370d7b8150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.981, 0.989)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cot_pred_proc==gt).mean(), (correction_proc==gt).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e52bb6ea-ddda-4743-918d-e8c75e0a9bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([152, 310, 333, 336, 346, 382, 402, 505, 549, 582, 587, 601, 726,\n",
       "       753, 850, 888, 903])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmatched_index=np.where(correction_proc!=cot_pred_proc)[0]\n",
    "correction_index=np.where(correction_proc==gt)[0]\n",
    "index=unmatched_index[np.where(np.isin(unmatched_index, correction_index))[0]]\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f0386702-d884-4afc-a49e-b95d2ab5dfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine whether the sidewalk runs alongside the road, we evaluate the three conditions: parallelism, clearance, and overlap. Let's go through each condition step by step.\n",
      "\n",
      "---\n",
      "\n",
      "### 1. **Parallelism**:\n",
      "The `min_angle` value measures the smallest angle between the sidewalk and the road. For the sidewalk to be considered parallel to the road, this value should be relatively small (e.g., less than 10–15 degrees). \n",
      "\n",
      "- **Given**: `min_angle = 5.802232362551285`\n",
      "- **Evaluation**: The angle is very small (less than 10 degrees), indicating that the sidewalk and road are approximately parallel. This condition is satisfied.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. **Clearance**:\n",
      "The `min_distance` value represents the minimum distance between the sidewalk and the road. A sidewalk running alongside a road should maintain a reasonable distance without intersecting or overlapping with the road. A typical threshold for this distance could be greater than 2–3 meters.\n",
      "\n",
      "- **Given**: `min_distance = 7.587268867058914`\n",
      "- **Evaluation**: The distance is greater than 7 meters, which is well within the acceptable range. This condition is satisfied.\n",
      "\n",
      "---\n",
      "\n",
      "### 3. **Overlap**:\n",
      "The `max_area` value indicates the maximum percentage of overlapping area between the sidewalk and road when considering a 10-meter buffer around each geometry. While the sidewalk and road must not directly overlap, their buffers should have some degree of overlap. A typical threshold might be greater than 20% (0.2).\n",
      "\n",
      "- **Given**: `max_area = 0.23506250658115269`\n",
      "- **Evaluation**: The overlap percentage is slightly above 20%, meaning there is sufficient interaction between the buffered regions of the sidewalk and road. This condition is satisfied.\n",
      "\n",
      "---\n",
      "\n",
      "### Final Decision:\n",
      "All three conditions (parallelism, clearance, and overlap) are satisfied. Therefore, the sidewalk does run alongside the road.\n",
      "\n",
      "### **Response**: `1`\n"
     ]
    }
   ],
   "source": [
    "#12, 13\n",
    "i=12\n",
    "print(cot_pred[index[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "6f376946-120d-429f-947e-81bfb7b2765e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upon reviewing the provided data and conditions, let's analyze whether the response is correct:\n",
      "\n",
      "1. **Parallelism (min_angle):**  \n",
      "   The `min_angle` value is 5.802°, which indicates that the sidewalk and road are fairly parallel since the angle difference is small. This condition appears to be satisfied.\n",
      "\n",
      "2. **Clearance (min_distance):**  \n",
      "   The `min_distance` value is 7.587 meters. This suggests there is a reasonable clearance between the sidewalk and the road, satisfying the clearance requirement.\n",
      "\n",
      "3. **Overlap (max_area):**  \n",
      "   The `max_area` value is 0.235, which represents the percentage of overlapping area within a 10-meter buffer. A value this low indicates minimal overlap between the sidewalk and road buffers. Typically, for a sidewalk to be considered alongside a road, we expect this value to be higher—close to or above 0.4 (as seen in the second example). \n",
      "\n",
      "Given these conditions:\n",
      "- Parallelism: Satisfied.\n",
      "- Clearance: Satisfied.\n",
      "- Overlap: Not satisfied (value too low).\n",
      "\n",
      "Based on the criteria described, the overlap condition fails because the `max_area` value is too small, suggesting insufficient spatial association between the sidewalk and the road despite their proximity and alignment.\n",
      "\n",
      "### Conclusion:\n",
      "The response **0** is correct. There is no issue with the provided response.\n"
     ]
    }
   ],
   "source": [
    "print(reviews[index[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0bbdae09-778d-48e0-94f2-83001765f9cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt[index[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00d9758-fb9c-4f24-a15c-db6f354c1eae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4761fb5-f96c-4d55-aac9-afd07e66159f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3373239f-3901-4d12-a78a-314f1a610949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a9804f-ac51-4ae1-b935-7a8acf458fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c30fe8-c0d6-48cf-9949-b451ce99674a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d08983a-51dc-4a96-8934-0ed8e1821278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cf8ece-8426-487b-b0f7-b04121ab7e21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52558ee-8815-4111-b7c6-53ff87149d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccdc0d8-57b0-44e5-a231-a5873a31225a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d4b87a-2902-4487-bad5-6ab25c1557e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
